\documentclass[12pt,oneside]{article}
\usepackage[margin=0.5in,bottom=.45in,top=.45in]{geometry}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{verbatim}
\usepackage{color}
\usepackage[font={small}]{caption}
\usepackage{mdframed}
\newcommand{\tab}{\hspace*{2em}}
\begin{document}
\title{Supervised Machine Learning Analysis}
\author{My Name, My Email}

\maketitle
\graphicspath{ { image/ } }

\section*{Introduction}

\section*{Data acquisition}

\subsection*{Dataset}

\section*{Tools Used and Methodology}

A jython interface to Weka\cite{weka-2009} is used to find error using different amounts of training data against a fixed test set.  This data is plotted using R and finally a latex report is generated.

\section*{K-Nearest Neighbors}

Find an optimal K by looking at the plot below.  Plug this value of K into ml.properties file.  Once domain knowledge values have been set for all algorithms, re-run the data generation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/k_nearest_neighbor_tunable_iris_rmse.png}


Fixed test set evaluated against a variable training set size and also trained against itself.  Plot to the right uses 10 fold cross validation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/k_nearest_neighbor_iris0_instances.png}
\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/k_nearest_neighbor_iris1_instances.png}

\section*{Decision trees with pruning}

Find an optimal confidence factor by looking at the below plot.  Plug this value into ml.properties file.  Once domain knowledge values have been set for all algorithms, re-run the data generation.

\includegraphics[scale=0.4,natwidth=1024,natheight=720]{image/j48_tree_tunable_iris_0.25.png}

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/j48_tree_tunable_iris_rmse.png}

Fixed test set evaluated against a variable training set size and also trained against itself.  Plot to the right uses 10 fold cross validation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/j48_tree_iris0_instances.png}
\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/j48_tree_iris1_instances.png}

\section*{Boosting}

Find an optimal value for number of iterations and then plug it into ml.properties file.  Once domain knowledge values have been set for all algorithms, re-run the data generation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/ada_boost_tunable_iris_rmse.png}
\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/ada_boost_tunable_iris_wall.png}

Fixed test set evaluated against a variable training set size and also trained against itself.  Plot to the right uses 10 fold cross validation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/ada_boost_iris0_instances.png}
\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/ada_boost_iris1_instances.png}

\section*{Neural Networks}

Find an optimal value for number of epochs and set it in ml.properties file.  This can help avoid long run times.  Once domain knowledge values have been set for all algorithms, re-run the data generation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/neural_network_tunable_iris_rmse.png}
\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/neural_network_tunable_iris_wall.png}

Fixed test set evaluated against a variable training set size and also trained against itself.  Plot to the right uses 10 fold cross validation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/neural_network_iris0_instances.png}
\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/neural_network_iris1_instances.png}

\section*{Support Vector Machines}

You need to find an optimal value of C and then plug it into the ml.properties file.  Once domain knowledge values have been set for all algorithms, re-run the data generation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/support_vector_machine_tunable_iris_rmse.png}

Fixed test set evaluated against a variable training set size and also trained against itself.  Plot to the right uses 10 fold cross validation.

\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/support_vector_machine_iris0_instances.png}
\includegraphics[scale=0.26,natwidth=1024,natheight=720]{image/support_vector_machine_iris1_instances.png}


\nocite{*}
\bibliographystyle{plain}
\bibliography{Master}
\end{document}
